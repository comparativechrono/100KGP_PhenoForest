{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comparativechrono/100KGP_PhenoForest/blob/main/PhenoTreev2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install and load required libraries"
      ],
      "metadata": {
        "id": "22kKYOgy1q1b"
      },
      "id": "22kKYOgy1q1b"
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"tidyverse\")\n",
        "install.packages(\"randomForest\")\n",
        "install.packages(\"caret\")\n",
        "install.packages(\"arules\")\n",
        "install.packages(\"arulesViz\")"
      ],
      "metadata": {
        "id": "SGiwvmgRh5-P"
      },
      "id": "SGiwvmgRh5-P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load necessary libraries\n",
        "library(tidyverse)\n",
        "library(randomForest)\n",
        "library(caret)\n",
        "library(arules)\n",
        "library(arulesViz)"
      ],
      "metadata": {
        "id": "j3Pwsr4vxucd"
      },
      "id": "j3Pwsr4vxucd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and preprocess the data"
      ],
      "metadata": {
        "id": "BqW0WH6DvZa7"
      },
      "id": "BqW0WH6DvZa7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data <- read.csv(\"brugada_phenotype_data.csv\")\n",
        "head(data)\n",
        "\n",
        "# Assume that phenotypes start from the 3rd column to the end\n",
        "phenotype_columns <- colnames(data)[3:ncol(data)]\n",
        "data[phenotype_columns] <- lapply(data[phenotype_columns], as.factor)\n",
        "\n",
        "# Preprocess the data\n",
        "data[phenotype_columns] <- lapply(data[phenotype_columns], as.factor)\n",
        "data$condition <- as.factor(data$condition)\n",
        "\n",
        "# Set conditions for doing rule mining\n",
        "conditions <- paste(\"condition=\", levels(data$condition), sep=\"\")\n",
        "\n",
        "# Keep patient IDs in a separate vector\n",
        "patient_ids <- data$patient_id\n",
        "\n",
        "# Remove patient_id column\n",
        "data <- data %>% select(-patient_id)\n"
      ],
      "metadata": {
        "id": "lSzw8r-yvcBD"
      },
      "id": "lSzw8r-yvcBD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Machine learning using Random Forest"
      ],
      "metadata": {
        "id": "aRCuxUu9vYrk"
      },
      "id": "aRCuxUu9vYrk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "set.seed(123)\n",
        "trainIndex <- createDataPartition(data$condition, p = .8,\n",
        "                                  list = FALSE,\n",
        "                                  times = 1)\n",
        "trainData <- data[ trainIndex,]\n",
        "testData  <- data[-trainIndex,]\n",
        "\n",
        "# Train a Random Forest model\n",
        "rf_model <- randomForest(condition ~ ., data = trainData, importance = TRUE, ntree = 500)\n",
        "\n",
        "# Predict on the test set\n",
        "predictions <- predict(rf_model, newdata = testData)\n",
        "\n",
        "# Evaluate the model\n",
        "confusionMatrix(predictions, testData$condition)\n",
        "\n",
        "# Extract feature importance\n",
        "importance <- importance(rf_model)\n",
        "varImportance <- data.frame(Phenotype = row.names(importance),\n",
        "                            Importance = round(importance[ , 'MeanDecreaseGini'], 2))\n",
        "\n",
        "# Rank the phenotypes by importance\n",
        "rankedImportance <- varImportance %>%\n",
        "  arrange(desc(Importance))\n",
        "\n",
        "# Create the ggplot object\n",
        "importance_plot <- ggplot(rankedImportance, aes(x = reorder(Phenotype, Importance), y = Importance)) +\n",
        "  geom_bar(stat = 'identity') +\n",
        "  coord_flip() +\n",
        "  labs(title = \"Phenotype Importance\",\n",
        "       x = \"Phenotype\",\n",
        "       y = \"Importance\")\n",
        "\n",
        "# Save the plot\n",
        "ggsave(\"phenotype_importance.png\", plot = importance_plot, width = 10, height = 8, units = \"in\")\n",
        "\n",
        "\n",
        "# Save the importance to a CSV file\n",
        "write.csv(rankedImportance, \"phenotype_importance.csv\", row.names = FALSE)\n",
        "\n",
        "# Association Rule Mining\n",
        "# Convert condition to a transaction format and add to the data\n",
        "data$condition <- as.factor(data$condition)\n",
        "transactions_with_condition <- as(data, \"transactions\")\n",
        "\n",
        "# Generate rules with condition included\n",
        "rules_with_condition <- apriori(transactions_with_condition, parameter = list(supp = 0.1, conf = 0.8))\n",
        "\n",
        "# Subset rules where the condition is in the RHS\n",
        "condition_rules <- subset(rules_with_condition, subset = rhs %in% conditions)\n",
        "\n",
        "# Sort and inspect top rules\n",
        "top_rules <- sort(condition_rules, by = \"lift\")[1:10]\n",
        "\n",
        "# Helper function to clean and split rule items\n",
        "clean_split_items <- function(items) {\n",
        "  items <- gsub(\"[{}]\", \"\", items) # Remove curly braces\n",
        "  strsplit(items, \",\")[[1]] # Split by comma\n",
        "}\n",
        "\n",
        "# Helper function to create human-readable rule text\n",
        "create_rule_text <- function(lhs, rhs) {\n",
        "  lhs <- gsub(\"[{}]\", \"\", lhs)\n",
        "  rhs <- gsub(\"[{}]\", \"\", rhs)\n",
        "  paste(lhs, \"=>\", rhs)\n",
        "}\n",
        "\n",
        "# Create a dataframe to hold the formatted rules\n",
        "rules_df <- data.frame(\n",
        "  Rule = sapply(1:length(top_rules), function(i) {\n",
        "    lhs_text <- paste(clean_split_items(labels(lhs(top_rules[i]))[[1]]), collapse=\", \")\n",
        "    rhs_text <- paste(clean_split_items(labels(rhs(top_rules[i]))[[1]]), collapse=\", \")\n",
        "    create_rule_text(lhs_text, rhs_text)\n",
        "  }),\n",
        "  Support = quality(top_rules)$support,\n",
        "  Confidence = quality(top_rules)$confidence,\n",
        "  Lift = quality(top_rules)$lift,\n",
        "  stringsAsFactors = FALSE\n",
        ")\n",
        "\n",
        "# Save to CSV\n",
        "write.csv(rules_df, \"top_rules.csv\", row.names = FALSE)\n",
        "\n",
        "# Prepare a data frame to store the results of patient IDs\n",
        "results <- data.frame(Rule = character(), Patient_ID = character(), stringsAsFactors = FALSE)\n",
        "\n",
        "# Report back the patient IDs that fall into each of the top 10 rules\n",
        "for (i in 1:length(top_rules)) {\n",
        "  rule <- top_rules[i]\n",
        "  lhs_items <- labels(lhs(rule))[[1]]\n",
        "  rhs_items <- labels(rhs(rule))[[1]]\n",
        "\n",
        "  # Clean and split items\n",
        "  lhs_items <- clean_split_items(lhs_items)\n",
        "  rhs_items <- clean_split_items(rhs_items)\n",
        "\n",
        "  # Combine lhs and rhs items to create a full rule match condition\n",
        "  items <- c(lhs_items, rhs_items)\n",
        "  rule_text <- create_rule_text(labels(lhs(rule)), labels(rhs(rule)))\n",
        "\n",
        "  # Convert items to a list format suitable for subsetting\n",
        "  items_list <- lapply(items, function(item) {\n",
        "    parts <- strsplit(item, \"=\")[[1]]\n",
        "    feature <- parts[1]\n",
        "    value <- parts[2]\n",
        "    if (feature %in% colnames(data)) {\n",
        "      condition <- data[[feature]] == value\n",
        "      return(condition)\n",
        "    } else {\n",
        "      return(rep(FALSE, nrow(data)))\n",
        "    }\n",
        "  })\n",
        "\n",
        "  # Subset the data to get the indices of rows that match the rule\n",
        "  matching_indices <- which(Reduce(\"&\", items_list))\n",
        "\n",
        "  matching_patients <- patient_ids[matching_indices]\n",
        "\n",
        "  # Append the results to the data frame\n",
        "  for (patient_id in matching_patients) {\n",
        "    results <- rbind(results, data.frame(Rule = paste(\"Rule\", i), Rule_Text = rule_text, Patient_ID = patient_id, stringsAsFactors = FALSE))\n",
        "  }\n",
        "}\n",
        "# Save the results to a CSV file\n",
        "write.csv(results, \"rule_matches.csv\", row.names = FALSE)\n",
        "\n",
        "# Open a PNG device for the graph plot\n",
        "png(\"filtered_rules_graph.png\", width = 800, height = 600)\n",
        "\n",
        "# Generate the plot with the graph method\n",
        "plot(condition_rules, method = \"graph\", limit = 20)\n",
        "\n",
        "# Close the device to save the file\n",
        "dev.off()\n",
        "\n",
        "# Open a PNG device for the grouped plot\n",
        "png(\"filtered_rules_grouped.png\", width = 800, height = 600)\n",
        "\n",
        "# Generate the plot with the grouped method\n",
        "plot(condition_rules, method = \"grouped\")\n",
        "\n",
        "# Close the device to save the file\n",
        "dev.off()\n",
        "\n",
        "quality(condition_rules) <- cbind(quality(condition_rules),\n",
        "                                  interestMeasure(condition_rules, measure = c(\"phi\", \"gini\"), trans = transactions_with_condition))\n",
        "\n",
        "top_rules_phi <- head(sort(condition_rules, by = \"phi\"), n = 100)\n",
        "\n",
        "# Open a PNG device\n",
        "png(\"top_100_rules_by_phi.png\", width = 800, height = 600)\n",
        "\n",
        "# Generate the plot\n",
        "plot(top_rules_phi, method = \"graph\",\n",
        "     control = list(layout = \"stress\",  # Choose a suitable layout algorithm\n",
        "                    circular = FALSE,   # Non-circular layout\n",
        "                    engine = \"ggplot2\", # Using ggplot2 for better quality\n",
        "                    main = \"Top 100 Rules by Phi\"))\n",
        "\n",
        "# Close the device to save the file\n",
        "dev.off()\n"
      ],
      "metadata": {
        "id": "PuNiagE6h2rX"
      },
      "id": "PuNiagE6h2rX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.5.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}